{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for loading data in training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_path, label_path=None, input_len=16, mode='train', sr=32000, input_dim=63):\n",
    "        self.input_len = input_len\n",
    "        self.mode = mode\n",
    "        gt = pd.read_csv(label_path)\n",
    "        self.mfcc_samples = torch.zeros((gt.shape[0]+input_len, input_dim), dtype=torch.float)\n",
    "\n",
    "        for i, path in enumerate(gt['track']):\n",
    "            y, sr = librosa.load(os.path.join(data_path, path), sr=32000)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=1).squeeze()\n",
    "            mfcc_norm = librosa.util.normalize(mfcc)\n",
    "            mfcc_norm = torch.from_numpy(mfcc_norm).float()\n",
    "            self.mfcc_samples[i+input_len] = mfcc_norm\n",
    "\n",
    "        if mode == 'train':        \n",
    "            self.target = torch.stack([torch.tensor(score) for score in gt['score']])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        output = self.mfcc_samples[index:index+self.input_len]\n",
    "        if self.mode == 'train':\n",
    "            target = self.target[index]\n",
    "            return  output, target\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc_samples)-self.input_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_regression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "    def forward(self, _x):\n",
    "        x, h_n = self.gru(_x)\n",
    "        s, b, h = x.shape\n",
    "        x = x.reshape(s*b, h)\n",
    "        x = self.fc(x)\n",
    "        x = x.reshape(s, b, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "input_len = 32\n",
    "input_dim = 313\n",
    "hidden_dim = 32\n",
    "sr = 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([1, 1, 1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.004354401041695\n"
     ]
    }
   ],
   "source": [
    "dataset_train = Dataset('audios/clips','train.csv', input_len=input_len, \\\n",
    "                        mode='train', sr=sr, input_dim=input_dim)\n",
    "    \n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "loss_function = nn.MSELoss()\n",
    "model = GRU_regression(input_dim, hidden_size=hidden_dim, num_layers=1)\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=0.2)\n",
    " \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    " \n",
    "model = model.to(device)\n",
    " \n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    losses = 0\n",
    "    for x, t in train_loader:\n",
    "        opt.zero_grad()\n",
    "        x = x.squeeze().reshape(input_len, 1, input_dim).to(device)\n",
    "        \n",
    "        t = t.reshape(-1, 1, 1).to(device)\n",
    "        out = model(x)\n",
    "        loss = loss_function(out[-1].sigmoid(), t)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        losses += loss.item()\n",
    "    print(losses)\n",
    "\n",
    "torch.save(model.state_dict(), 'model_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4982593059539795\n",
      "0.6349506974220276\n",
      "0.6489795446395874\n",
      "0.6753785610198975\n",
      "0.700973629951477\n",
      "0.7097406387329102\n",
      "0.7189907431602478\n",
      "0.7095629572868347\n",
      "0.7145441174507141\n",
      "0.7021209597587585\n",
      "0.708186149597168\n",
      "0.7187498211860657\n",
      "0.7108915448188782\n",
      "0.6995230913162231\n",
      "0.6997758150100708\n"
     ]
    }
   ],
   "source": [
    "model = model.eval()\n",
    "dataset_test = Dataset('audios/clips','test.csv', input_len=input_len, mode='test', sr=sr, input_dim=input_dim)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "for x in test_loader:\n",
    "    x = x.squeeze().reshape(input_len, 1, input_dim).to(device)\n",
    "    out = model(x)\n",
    "    out = out[-1].sigmoid()\n",
    "    print(out.item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
